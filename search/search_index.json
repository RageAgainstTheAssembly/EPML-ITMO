{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"EPML ITMO \u2014 Wine Predictor","text":"<p>This repository contains a project project for ML/DL Engineering Practices course: - Poetry dependency management - DVC pipeline (train \u2192 evaluate \u2192 notify) - MLflow experiment tracking - ClearML tracking + pipeline - OmegaConf configuration - and more</p>"},{"location":"#quickstart","title":"Quickstart","text":"<pre><code>git clone https://github.com/RageAgainstTheAssembly/EPML-ITMO\ncd EPML-ITMO\npoetry install --with docs\npoetry run dvc repro\npoetry run python -m wine_predictor.reporting.generate_experiment_report\npoetry run mkdocs serve\n</code></pre>"},{"location":"deployment/","title":"Deployment","text":""},{"location":"deployment/#local-setup-poetry","title":"Local setup (Poetry)","text":"<pre><code>pip install --user poetry\npoetry config virtualenvs.in-project true\npoetry install --with docs\n</code></pre>"},{"location":"deployment/#run-the-dvc-pipeiline","title":"Run the DVC pipeiline","text":"<pre><code>poetry run dvc repro\n</code></pre>"},{"location":"deployment/#run-the-mlflow-ui","title":"Run the MLFlow UI","text":"<pre><code>poetry run mlflow ui \\\n  --backend-store-uri sqlite:///mlruns/mlflow.db \\\n  --default-artifact-root mlruns/artifacts \\\n  --host 127.0.0.1 \\\n  --port 5000\n</code></pre>"},{"location":"deployment/#run-docker","title":"Run Docker","text":"<pre><code>docker build -t epml-wine:dev .\ndocker run --rm epml-wine:dev\n</code></pre>"},{"location":"deployment/#run-local-clearml-server","title":"Run local CLearML server","text":"<p>Download the suggested <code>docker-compose.yml</code> file from Github, in its directory run: <pre><code>docker-compose up\n</code></pre> Then, use the UI to set up credentials and copy the access key. In the project directory run: <pre><code>poetry run clearml-init\n</code></pre> and paste the access key when prompted.</p>"},{"location":"hw5_report/","title":"HW 6","text":""},{"location":"hw5_report/#1-overview","title":"1. Overview","text":"<p>The point of HW 6 is setting up MKDocs and Github Action+Pages automation for our existing project. Also, from previous stages we inherit:</p> <ul> <li>Cookiecutter for the overall template</li> <li>Poetry for dependencies, convenient setup with pyproject</li> <li>Pre-commit hooks and linting (Black, isort, Ruff, MyPy, Bandit)</li> <li><code>wine_predictor</code> as a package</li> <li>Jupyter notebook solution using that package</li> <li>Docker reproducibility</li> <li>Git usage: starting out with pushing changes to <code>develop</code> branch, testing docker on <code>feature/docker</code>, finally pushing to <code>main</code></li> <li>DVC-based data and model versioning</li> <li>MLFlow experiment tracking and logging</li> <li>A multi stage (train-&gt;evaluate-&gt;notify) ML pipeline</li> <li>Structured composable configuration with OmegaConf</li> <li>ClearML tracking, model registry, pipeline</li> </ul> <p>In this HW we add: - MKDocs - Github Actions+Pages integration</p>"},{"location":"hw5_report/#a-few-notes-on-the-specifics","title":"A few notes on the specifics:","text":"<ul> <li>We use Wine Quality prediction as an example</li> <li>The actual ML pipeline is just a baseline solution, for now we don't really care about metrics</li> <li>Running the Docker container means running the training and printing the metrics by default</li> <li>A few folders from the template (e.g. <code>data/processed</code>) were kept even though they are not currently used in case we need them in the future</li> <li>We don't actually make and plots or figures, but keep those folders for the reason mentioned above</li> <li>Detailed tool configs can be found in the corresponding files (mainly <code>pyproject.toml</code>)</li> <li>Why DVC? Seemed versatile and simple enough. I like the parallels between DVC and Git.</li> <li>Why MLFlow? I've already used W&amp;B and TensorBoard. MLFlow was something I've been wanting to try for a while.</li> <li>Aside from MLFlow functionality, we track DVC pipeline progress entirely in console. We also apply the same logic to completion notifications, using <code>wine_predictor/pipelines/notify.py</code> as an example. Its logic could be replaced with a call to the Telegram API for a proper message-based notification system.</li> </ul>"},{"location":"hw5_report/#2-project-structure","title":"2. Project structure","text":""},{"location":"hw5_report/#3-dependency-management","title":"3. Dependency management","text":""},{"location":"hw5_report/#31-poetry","title":"3.1 Poetry","text":"<p>Poetry is used as the dependency manager</p> <p>This is a barebones example of using poetry to install our dependencies:</p> <pre><code>pip install --user poetry\n\npoetry config virtualenvs.in-project true\n\npoetry install\n</code></pre> <p>This creates <code>.venv/</code> inside the project and installs everything from <code>pyproject.toml</code> / <code>poetry.lock</code>.</p>"},{"location":"hw5_report/#32-pyprojecttoml","title":"3.2 pyproject.toml","text":"<p>It contains: * Project metadata * Python dependencies * Dev dependencies (linters, pre-commit hooks, jupyter) * Tool configuration</p> <p>Installing from scratch:</p> <pre><code>git clone https://github.com/RageAgainstTheAssembly/EPML-ITMO\ncd EPML_ITMO\npoetry install\n</code></pre>"},{"location":"hw5_report/#4-formatters-linters-pre-commit-hooks","title":"4. Formatters, linters, pre-commit hooks","text":"<ul> <li>Black \u2013 code formatter</li> <li>isort \u2013 import sorter</li> <li>Ruff \u2013 fast linter + auto-fixes</li> <li>MyPy \u2013 static type checker</li> <li>Bandit \u2013 security scanner</li> </ul> <p>Installing and running hooks:</p> <pre><code>poetry run pre-commit install\n\npoetry run pre-commit run --all-files\n</code></pre> <p></p>"},{"location":"hw5_report/#5-actual-ml-solution","title":"5. Actual ML solution","text":""},{"location":"hw5_report/#51-implementation","title":"5.1 Implementation","text":"<p>Won't be going into detail - it's essentially a basic SKLearn pipeline with a Logistic Regression classifier. Training a great ML model is not the point of this homework</p>"},{"location":"hw5_report/#53-running-from-a-notebook","title":"5.3 Running from a notebook","text":"<p>Solution in <code>notebooks/solution.ipynb</code> uses the package code to run training and inference.</p>"},{"location":"hw5_report/#6-jupyter-setup","title":"6. Jupyter setup","text":"<p>We use Jupyter to showcase usage and register a dedicated kernel:</p> <pre><code>poetry add --group dev jupyterlab ipykernel\n\npoetry run python -m ipykernel install --user --name epml-wine --display-name \"Python (epml_itmo)\"\n\npoetry run jupyter lab\n</code></pre>"},{"location":"hw5_report/#7-docker","title":"7. Docker","text":"<p>We provide a simple <code>Dockerfile</code> in the project root</p> <p>To build and run:</p> <p><pre><code>docker build -t epml-wine:dev .\n\ndocker run --rm epml-wine:dev\n</code></pre> This should train the model and print its metrics to console. Note that the docker image works as a demo, we didn't change it to use DVC itself.</p> <p> </p>"},{"location":"hw5_report/#8-versioning-tools","title":"8. Versioning tools","text":"<p>DVC was chosen because it's very versatile and also more distinct than Git LFS, which I already have some experience with. We use DVC for both data and model versioning, while also tracking hyperparams and metrics.</p>"},{"location":"hw5_report/#9-data-versioning","title":"9. Data versioning","text":"<p>We use a local remote to keep track of our only dataset - WineQT.csv</p>"},{"location":"hw5_report/#10-mlflow-setup-and-integration","title":"10. MLFlow setup and integration","text":"<p>We use MLFlow to track experiments for reasons outlined above.</p>"},{"location":"hw5_report/#101-setup","title":"10.1 Setup","text":"<p>MLFlow is added as a project dependency via Poetry: <pre><code>poetry add mlflow\n</code></pre> For convenience, we isolate all MLFlow helpers and utils in <code>wine_predictor/mlflow_utils.py</code></p>"},{"location":"hw5_report/#102-database-and-artifacts","title":"10.2 Database and artifacts","text":"<p>MLFlow is configured to run on top of a local SQLite DB and a local artifact directory: Tracking DB URI: sqlite:///mlruns/mlflow.db Artifact location: mlruns/artifacts</p> <p><code>configure_mlflow</code> handles basic configuration: <pre><code># wine_predictor/mlflow_utils.py\n\nDEFAULT_EXPERIMENT_NAME = \"wine_quality_hw3\"\nDEFAULT_TRACKING_URI = \"sqlite:///mlruns/mlflow.db\"\n\ndef configure_mlflow(\n    tracking_uri: str = DEFAULT_TRACKING_URI,\n    experiment_name: str = DEFAULT_EXPERIMENT_NAME,\n) -&gt; None:\n    mlflow.set_tracking_uri(tracking_uri)\n    mlflow.set_experiment(experiment_name)\n</code></pre> All runs are logged under a single MLFlow experiment.</p>"},{"location":"hw5_report/#103-authentication","title":"10.3 Authentication","text":"<p>Since we're running a local-only MLFlow setup and UI is bound to localhost, we don't really have any traditional authentication: <pre><code>poetry run mlflow ui \\\n  --backend-store-uri sqlite:///mlruns/mlflow.db \\\n  --default-artifact-root mlruns/artifacts \\\n  --host 127.0.0.1 \\\n  --port 5000\n</code></pre> By default, this means the UI can only be accessed from the local machine, so access comes down to local users' rights configuration. If we really wanted to emulate some kind of access restriction, we could do <pre><code>chmod -R go-rwx mlruns\n</code></pre> to make it so that only the current OS user can read/write tracking data.</p>"},{"location":"hw5_report/#104-code-integration","title":"10.4 Code integration","text":"<p>We use:</p> <ul> <li> <p><code>@training_run(...)</code> \u2013 decorator that wraps a training function into an MLflow run</p> </li> <li> <p><code>mlflow_run(...)</code> \u2013 context manager for the decorator</p> </li> </ul> <p><code>@training_run</code>:</p> <ul> <li> <p>Configures MLFlow (URI + experiment name)</p> </li> <li> <p>Starts and stops runs</p> </li> <li> <p>Logs params, metrics, artifacts, model and tags</p> </li> </ul> <p>The decorator is defined in <code>wine_predictor/mlflow_utils.py</code> and is used in <code>wine_predictor/modeling/train.py</code>. The updated training code uses the new decorators and builds a trainining pipeline with the provided params.</p>"},{"location":"hw5_report/#105-launching-a-single-run","title":"10.5 Launching a single run","text":"<p>To launch a single run with <code>params.yaml</code>: <pre><code>poetry run python -m wine_predictor.modeling.train\n</code></pre></p>"},{"location":"hw5_report/#106-launching-a-grid-of-experiments","title":"10.6 Launching a grid of experiments","text":"<p>To launch an entire grid of training runs: <pre><code>poetry run python -m wine_predictor.experiments\n</code></pre> All the params that define the grid can be found in <code>wine_predictor/experiments.py</code></p>"},{"location":"hw5_report/#11-mlflow-usage","title":"11. MLFlow usage","text":"<p>To run the UI: <pre><code>poetry run mlflow ui \\\n  --backend-store-uri sqlite:///mlruns/mlflow.db \\\n  --default-artifact-root mlruns/artifacts \\\n  --host 127.0.0.1 \\\n  --port 5000\n</code></pre> Once you've selected the experiment, you should see of all your logged runs:  Built-in functionality allows you to search and filter by metrics, values, time created, state. You can also sort and open additional columns with all of your tracked params.  For example, you could: Filter runs by tags:</p> <ul> <li><code>tags.hw = \"3\"</code></li> <li><code>tags.experiment = \"grid\"</code></li> <li><code>tags.algorithm = \"random_forest\"</code></li> </ul> <p>Sort by: <code>metrics.accuracy DESC</code></p> <p>Select several runs and click <code>Compare</code> to see:</p> <ul> <li>parallel coordinate plots</li> <li>metric vs parameter plots (e.g. accuracy vs C)</li> <li>individual run details (artifacts, params, tags)</li> </ul> <p>MLFlow also makes it easy to visualise key metrics:  Clicking on a specific run will allow you to see its details and params, as well as information on run artifacts: </p>"},{"location":"hw5_report/#12-dvc-ml-pipeline-and-omegaconf-configuration","title":"12. DVC ML pipeline and OmegaConf configuration","text":""},{"location":"hw5_report/#121-why-dvc","title":"12.1 Why DVC?","text":"<ul> <li>Fairly lightweight and simple</li> <li>Already integrated for data versioning in previous stages of this project</li> <li>Supports all the essential features like stages, dependency tracking, caching, parallel execution</li> </ul>"},{"location":"hw5_report/#122-dvc-pipeline-setup","title":"12.2 DVC pipeline setup","text":"<p>In practice, we implement the pipeline by changing <code>dvc.yaml</code> from a single <code>train</code> stage to <code>train</code>-&gt;<code>evaluate</code>-&gt;<code>notify</code>: <pre><code>stages:\n  train:\n    cmd: poetry run python -m wine_predictor.modeling.train --model logreg\n    deps:\n      - data/external/WineQT.csv\n      - wine_predictor/dataset.py\n      - wine_predictor/features.py\n      - wine_predictor/modeling/train.py\n      - wine_predictor/config.py\n      - configs/train/base.yaml\n      - configs/model/logreg.yaml\n    outs:\n      - models/baseline_model.joblib\n    metrics:\n      - metrics.json:\n          cache: false\n\n  evaluate:\n    cmd: poetry run python -m wine_predictor.pipelines.evaluate\n    deps:\n      - models/baseline_model.joblib\n      - wine_predictor/pipelines/evaluate.py\n      - wine_predictor/dataset.py\n      - wine_predictor/features.py\n      - wine_predictor/config.py\n    metrics:\n      - reports/metrics_detailed.json:\n          cache: false\n\n  notify:\n    cmd: poetry run python -m wine_predictor.pipelines.notify\n    deps:\n      - reports/metrics_detailed.json\n      - wine_predictor/pipelines/notify.py\n    always_changed: true\n</code></pre> We set <code>always_changed: true</code> for <code>notify</code> stage to make sure it actually runs every time, even when we're reproducing existing results.</p> <p>This configuration results in a fairly simple DAG: </p>"},{"location":"hw5_report/#123-dvc-pipeline-usage","title":"12.3 DVC pipeline usage","text":"<p>In order to run the pipeline with all its stages, run <pre><code>poetry run dvc repro\n</code></pre> This will run <code>train</code>, <code>evaluate</code> and <code>notify</code> sequentially. Initiating another run without changes will lead to the following behaviour:  Caching will ensure unchanged stages (<code>train</code>, <code>evaluate</code>) do not run again. Instead, only the pipeline completion notification stage <code>notify</code> will run to show results.</p> <p>DVC also supports running multiple jobs in parallel <pre><code>poetry run dvc repro -j 2\n</code></pre> although our pipeline is not suited to parallel execution, as it lacks independent stages.</p> <p>The console output of the various stages is used in conjunction with the <code>notify</code> stage to keep track of execution, errors and results.</p>"},{"location":"hw5_report/#124-why-omegaconf","title":"12.4 Why OmegaConf?","text":"<ul> <li>Easy to use with YAML files</li> <li>Supports the necessary features</li> <li>Pretty lightweight and easy to add to our existing code</li> </ul>"},{"location":"hw5_report/#125-omegaconf-usage","title":"12.5 OmegaConf usage","text":"<ul> <li>Loading base training configuration from <code>configs/train/base.yaml</code></li> <li>Loading algorithm-specific configurations from <code>configs/model/*.yaml</code></li> <li>Providing these configs to the training code in a composable way</li> </ul> <p>Configs are stored in a dedicated <code>configs/</code> directory: <pre><code>configs/\n\u251c\u2500\u2500 train\n\u2502   \u2514\u2500\u2500 base.yaml\n\u2514\u2500\u2500 model\n    \u251c\u2500\u2500 logreg.yaml\n    \u251c\u2500\u2500 random_forest.yaml\n    \u2514\u2500\u2500 gradient_boosting.yaml\n</code></pre> <code>wine_predictor/config.py</code> integrates OmegaConf and performs extra validation.</p> <p>We also add some validation on top to make sure configs are checked for broken values.</p> <p>Overall, we're using the following hierarchy: base -&gt; model-type -&gt; per-run overrides.</p>"},{"location":"hw5_report/#13-clearml-server-setup","title":"13. ClearML Server setup","text":""},{"location":"hw5_report/#131-local-server-via-docker-compose","title":"13.1 Local server via docker-compose","text":"<p>We use the <code>docker-compose.yml</code> recommended by ClearML docs. This makes it easy to launch the server with <pre><code>docker-compose up\n</code></pre> For reference, the <code>docker-compose.yml</code> is included below: <pre><code>version: \"3.6\"\nservices:\n\n  apiserver:\n    command:\n    - apiserver\n    container_name: clearml-apiserver\n    image: clearml/server:latest\n    restart: unless-stopped\n    volumes:\n    - /opt/clearml/logs:/var/log/clearml\n    - /opt/clearml/config:/opt/clearml/config\n    - /opt/clearml/data/fileserver:/mnt/fileserver\n    depends_on:\n      - redis\n      - mongo\n      - elasticsearch\n      - fileserver\n    environment:\n      CLEARML_ELASTIC_SERVICE_HOST: elasticsearch\n      CLEARML_ELASTIC_SERVICE_PORT: 9200\n      CLEARML_MONGODB_SERVICE_HOST: mongo\n      CLEARML_MONGODB_SERVICE_PORT: 27017\n      CLEARML_REDIS_SERVICE_HOST: redis\n      CLEARML_REDIS_SERVICE_PORT: 6379\n      CLEARML_SERVER_DEPLOYMENT_TYPE: linux\n      CLEARML__apiserver__pre_populate__enabled: \"true\"\n      CLEARML__apiserver__pre_populate__zip_files: \"/opt/clearml/db-pre-populate\"\n      CLEARML__apiserver__pre_populate__artifacts_path: \"/mnt/fileserver\"\n      CLEARML__services__async_urls_delete__enabled: \"true\"\n      CLEARML__services__async_urls_delete__fileserver__url_prefixes: \"[${CLEARML_FILES_HOST:-}]\"\n      CLEARML__secure__credentials__services_agent__user_key: ${CLEARML_AGENT_ACCESS_KEY:-}\n      CLEARML__secure__credentials__services_agent__user_secret: ${CLEARML_AGENT_SECRET_KEY:-}\n    ports:\n    - \"8008:8008\"\n    networks:\n      - backend\n      - frontend\n\n  elasticsearch:\n    networks:\n      - backend\n    container_name: clearml-elastic\n    environment:\n      bootstrap.memory_lock: \"true\"\n      cluster.name: clearml\n      cluster.routing.allocation.node_initial_primaries_recoveries: \"500\"\n      cluster.routing.allocation.disk.watermark.low: 500mb\n      cluster.routing.allocation.disk.watermark.high: 500mb\n      cluster.routing.allocation.disk.watermark.flood_stage: 500mb\n      discovery.type: \"single-node\"\n      http.compression_level: \"7\"\n      node.name: clearml\n      reindex.remote.whitelist: \"'*.*'\"\n      xpack.security.enabled: \"false\"\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n      nofile:\n        soft: 65536\n        hard: 65536\n    image: elasticsearch:8.17.0\n    restart: unless-stopped\n    volumes:\n      - /opt/clearml/data/elastic_7:/usr/share/elasticsearch/data\n      - /usr/share/elasticsearch/logs\n\n  fileserver:\n    networks:\n      - backend\n      - frontend\n    command:\n    - fileserver\n    container_name: clearml-fileserver\n    image: clearml/server:latest\n    environment:\n      CLEARML__fileserver__delete__allow_batch: \"true\"\n    restart: unless-stopped\n    volumes:\n    - /opt/clearml/logs:/var/log/clearml\n    - /opt/clearml/data/fileserver:/mnt/fileserver\n    - /opt/clearml/config:/opt/clearml/config\n    ports:\n    - \"8081:8081\"\n\n  mongo:\n    networks:\n      - backend\n    container_name: clearml-mongo\n    image: mongo:7.0.22\n    restart: unless-stopped\n    command: --setParameter internalQueryMaxBlockingSortMemoryUsageBytes=196100200\n    volumes:\n    - /opt/clearml/data/mongo_4/db:/data/db\n    - /opt/clearml/data/mongo_4/configdb:/data/configdb\n\n  redis:\n    networks:\n      - backend\n    container_name: clearml-redis\n    image: redis:7.4.1\n    restart: unless-stopped\n    volumes:\n    - /opt/clearml/data/redis:/data\n\n  webserver:\n    command:\n    - webserver\n    container_name: clearml-webserver\n    # environment:\n    #  CLEARML_SERVER_SUB_PATH : clearml-web # Allow Clearml to be served with a URL path prefix.\n    image: clearml/server:latest\n    restart: unless-stopped\n    depends_on:\n      - apiserver\n    ports:\n    - \"8080:80\"\n    networks:\n      - backend\n      - frontend\n\n  async_delete:\n    depends_on:\n      - apiserver\n      - redis\n      - mongo\n      - elasticsearch\n      - fileserver\n    container_name: async_delete\n    image: clearml/server:latest\n    networks:\n      - backend\n    restart: unless-stopped\n    environment:\n      CLEARML_ELASTIC_SERVICE_HOST: elasticsearch\n      CLEARML_ELASTIC_SERVICE_PORT: 9200\n      CLEARML_MONGODB_SERVICE_HOST: mongo\n      CLEARML_MONGODB_SERVICE_PORT: 27017\n      CLEARML_REDIS_SERVICE_HOST: redis\n      CLEARML_REDIS_SERVICE_PORT: 6379\n      PYTHONPATH: /opt/clearml/apiserver\n      CLEARML__services__async_urls_delete__fileserver__url_prefixes: \"[${CLEARML_FILES_HOST:-}]\"\n    entrypoint:\n      - python3\n      - -m\n      - jobs.async_urls_delete\n      - --fileserver-host\n      - http://fileserver:8081\n    volumes:\n      - /opt/clearml/logs:/var/log/clearml\n      - /opt/clearml/config:/opt/clearml/config\n\n  agent-services:\n    networks:\n      - backend\n    container_name: clearml-agent-services\n    image: clearml/clearml-agent-services:latest\n    deploy:\n      restart_policy:\n        condition: on-failure\n    privileged: true\n    environment:\n      CLEARML_HOST_IP: ${CLEARML_HOST_IP}\n      CLEARML_WEB_HOST: ${CLEARML_WEB_HOST:-}\n      CLEARML_API_HOST: http://apiserver:8008\n      CLEARML_FILES_HOST: ${CLEARML_FILES_HOST:-}\n      CLEARML_API_ACCESS_KEY: ${CLEARML_AGENT_ACCESS_KEY:-$CLEARML_API_ACCESS_KEY}\n      CLEARML_API_SECRET_KEY: ${CLEARML_AGENT_SECRET_KEY:-$CLEARML_API_SECRET_KEY}\n      CLEARML_AGENT_GIT_USER: ${CLEARML_AGENT_GIT_USER}\n      CLEARML_AGENT_GIT_PASS: ${CLEARML_AGENT_GIT_PASS}\n      CLEARML_AGENT_UPDATE_VERSION: ${CLEARML_AGENT_UPDATE_VERSION:-&gt;=0.17.0}\n      CLEARML_AGENT_DEFAULT_BASE_DOCKER: \"ubuntu:18.04\"\n      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}\n      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}\n      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION:-}\n      AZURE_STORAGE_ACCOUNT: ${AZURE_STORAGE_ACCOUNT:-}\n      AZURE_STORAGE_KEY: ${AZURE_STORAGE_KEY:-}\n      GOOGLE_APPLICATION_CREDENTIALS: ${GOOGLE_APPLICATION_CREDENTIALS:-}\n      CLEARML_WORKER_ID: \"clearml-services\"\n      CLEARML_AGENT_DOCKER_HOST_MOUNT: \"/opt/clearml/agent:/root/.clearml\"\n      SHUTDOWN_IF_NO_ACCESS_KEY: 1\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /opt/clearml/agent:/root/.clearml\n    depends_on:\n      - apiserver\n    entrypoint: &gt;\n      bash -c \"curl --retry 10 --retry-delay 10 --retry-connrefused 'http://apiserver:8008/debug.ping' &amp;&amp; /usr/agent/entrypoint.sh\"\n\nnetworks:\n  backend:\n    driver: bridge\n  frontend:\n    driver: bridge\n</code></pre></p>"},{"location":"hw5_report/#132-clearml-components","title":"13.2 ClearML components","text":"<p>Docker launches the standard services needed for ClearML: - clearml-webserver - clearml-apiserver - clearml-fileserver - async_delete - MongoDB - Elasticsearch - Redis</p>"},{"location":"hw5_report/#133-authentication","title":"13.3 Authentication","text":"<p>We create a user in the ClearML UI, generate an API key. Then, inside the project directory we can run <pre><code>poetry add clearml\npoetry run clearml-init\n</code></pre> and paste the credentials for the local server. We do not configure any additional access restrictions. </p>"},{"location":"hw5_report/#14-clearml-integration","title":"14. ClearML integration","text":""},{"location":"hw5_report/#141-code-integration","title":"14.1 Code integration","text":"<p>ClearML integration is implemented in <code>wine_predictor/clearml_utils.py</code>, including helper functions and a decorator. This is done mostly to ensure actual pipeline code stays simple and readable.</p>"},{"location":"hw5_report/#142-clearml-tracking","title":"14.2 ClearML tracking","text":"<p>We log parameters to ClearML:   We also track and plot training metrics (in this case, accuracy): </p>"},{"location":"hw5_report/#144-clearml-model-registry","title":"14.4 ClearML model registry","text":"<p>We track our models with ClearML model registry functionality, enabling model versioning and metadata tracking: </p>"},{"location":"hw5_report/#143-comparing-experiments","title":"14.3 Comparing experiments","text":"<p>We can easily visualise and compare metrics across experiments in the UI:  The same goes for comparing models in the registry: </p>"},{"location":"hw5_report/#151-clearml-pipeline","title":"15.1 ClearML pipeline","text":"<p>ClearML pipeline is implemented in  <code>wine_predictor/pipelines/clearml_pipeline.py</code>. It contains 3 steps, mirroring our previous DVC pipeline: - <code>step_train</code> - <code>step_evaluate</code> - <code>step_notify</code></p> <p>We run it locally with <pre><code>pipe.start_locally(run_pipeline_steps_locally=True)\n</code></pre> </p> <p>ClearML UI shows all 3 stages, their status and timings, as well as artifacts.</p>"},{"location":"hw5_report/#16-mkdocs-setup","title":"16. MKDocs setup","text":"<p>We use MkDocsto build a documentation website from Markdown files inside <code>docs/</code>. Key files:</p> <ul> <li><code>mkdocs.ym</code>l - main documentation configuration (navigation, theme, plugins)</li> <li><code>docs/index.md</code> - documentation homepage</li> <li><code>docs/deployment.md</code> - deployment guide</li> <li><code>docs/usage.md</code> - usage examples</li> <li><code>docs/reproducibility.md</code> - step-by-step reproduction guide</li> <li><code>docs/experiments/index.md</code> - experiments section landing page</li> <li><code>docs/api/index.md</code> - API reference landing page</li> </ul> <p>Local usage: <pre><code>poetry run mkdocs build\npoetry run mkdocs serve\n</code></pre></p> <p></p>"},{"location":"hw5_report/#17-api-reference-geneartion","title":"17. API reference geneartion","text":"<p>API reference is generated automatically when building documentation: - <code>mkdocstrings</code> renders API docs from Python modules - <code>mkdocs-gen-files</code> generates Markdown pages for each module</p> <p>Reference pages are generated by <code>scripts/gen_ref_pages.py</code> </p>"},{"location":"hw5_report/#18-experiment-report","title":"18. Experiment report","text":"<p><code>docs/experiments/experiments.md</code> contains a report with table and plot comparisons of existing MLFlow experiments. Note that MLFlow data is not accessible to Github Actions, so Github Pages will show a minimal report. To run locally: <pre><code>poetry run generate-experiment-report\n</code></pre> </p> <p>In order to make it automated and reproducible, we've added a <code>doc_report</code> stage to DVC, so you can just run <pre><code>poetry run dvc repro\n</code></pre></p>"},{"location":"hw5_report/#19-github-pages-publication-via-github-actions","title":"19. Github Pages publication via Github Actions","text":"<p>Documentation is deployed automatically via a workflow file <code>.github/workflows/docs.yml</code>. It follows these steps: - Install poetry - Install dependencies - Generate experiment report - Build docs - Deploy to Github Pages</p>"},{"location":"hw5_report/#20-reproducing-everything","title":"20. Reproducing everything","text":"<pre><code># 1. Clone\ngit clone https://github.com/RageAgainstTheAssembly/EPML-ITMO\ncd EPML-ITMO\ngit checkout main_hw3\n\n# 2. Poetry\npip install --user poetry\npoetry config virtualenvs.in-project true\n\n# 3. Dependencies\npoetry install --with docs\n\n# 4. Install pre-commit hooks and run them\npoetry run pre-commit install\npoetry run pre-commit run --all-files\n\n# 5. Get data and model artifacts from DVC remote (this assumes you have access to the remote)\npoetry run dvc remote modify local_remote url &lt;insert your remote path&gt;\npoetry run dvc pull\n\n# 6. Reproduce experiments\npoetry run dvc repro\n\n# 7. See docs\npoetry run mkdocs serve\n</code></pre>"},{"location":"reproducibility/","title":"Reproducibility","text":""},{"location":"reproducibility/#1-clone-and-install","title":"1. Clone and install","text":"<pre><code>git clone https://github.com/RageAgainstTheAssembly/EPML-ITMO\ncd EPML-ITMO\npoetry install --with docs\npoetry run dvc remote modify local_remote url &lt;insert your remote path&gt;\npoetry run dvc pull\n</code></pre>"},{"location":"reproducibility/#2-run-dvc-pipeline","title":"2. Run DVC pipeline","text":"<pre><code>poetry run dvc repro\n</code></pre>"},{"location":"reproducibility/#3-generate-report","title":"3. Generate report","text":"<pre><code>poetry run generate-experiment-report\n</code></pre>"},{"location":"reproducibility/#4-build-and-serve-docs","title":"4. Build and serve docs","text":"<pre><code>poetry run mkdocs build\npoetry run mkdocs serve\n</code></pre>"},{"location":"usage/","title":"Usage examples","text":""},{"location":"usage/#train-a-single-run","title":"Train a single run","text":"<pre><code>poetry run python -m wine_predictor.modeling.train --model logreg\n</code></pre>"},{"location":"usage/#run-an-experiment-grid","title":"Run an experiment grid","text":"<pre><code>poetry run python -m wine_predictor.experiments\n</code></pre>"},{"location":"usage/#run-the-dvc-pipeline","title":"Run the DVC pipeline","text":"<pre><code>poetry run dvc repro\n</code></pre>"},{"location":"usage/#run-the-clearml-pipeline","title":"Run the ClearML pipeline","text":"<pre><code>poetry run python -m wine_predictor.pipelines.clearml_pipeline --model logreg\n</code></pre>"},{"location":"api/","title":"API Reference","text":"<p>API pages are generated automatically from the <code>wine_predictor</code> package at documentation build time.</p>"},{"location":"experiments/","title":"Experiments","text":"<p>This section contains automatically generated experiment reports. Use:</p> <pre><code>poetry run generate-experiment-report\n</code></pre>"},{"location":"experiments/experiments/","title":"Experiment comparison","text":"<p>MLflow experiment: <code>wine_quality_hw3</code></p> <p>No MLflow runs found.</p> <p>Run experiments first:</p> <pre><code>poetry run python -m wine_predictor.experiments\n</code></pre>"},{"location":"reference/SUMMARY/","title":"Reference","text":"<ul> <li>wine_predictor<ul> <li>clearml_utils</li> <li>config</li> <li>dataset</li> <li>experiments</li> <li>features</li> <li>mlflow_utils</li> <li>modeling<ul> <li>predict</li> <li>train</li> </ul> </li> <li>pipelines<ul> <li>clearml_pipeline</li> <li>evaluate</li> <li>notify</li> </ul> </li> <li>reporting<ul> <li>generate_experiment_report</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/wine_predictor/clearml_utils/","title":"<code>wine_predictor.clearml_utils</code>","text":""},{"location":"reference/wine_predictor/clearml_utils/#wine_predictor.clearml_utils","title":"wine_predictor.clearml_utils","text":""},{"location":"reference/wine_predictor/config/","title":"<code>wine_predictor.config</code>","text":""},{"location":"reference/wine_predictor/config/#wine_predictor.config","title":"wine_predictor.config","text":""},{"location":"reference/wine_predictor/config/#wine_predictor.config.ProjectPaths","title":"ProjectPaths  <code>dataclass</code>","text":"<p>Common project paths resolved from this file location.</p>"},{"location":"reference/wine_predictor/config/#wine_predictor.config.TrainingConfig","title":"TrainingConfig  <code>dataclass</code>","text":"<p>Configuration for baseline wine quality model training.</p>"},{"location":"reference/wine_predictor/config/#wine_predictor.config.load_training_config","title":"load_training_config","text":"<pre><code>load_training_config() -&gt; TrainingConfig\n</code></pre> <p>Load training config from configs/train/base.yaml (if present)</p>"},{"location":"reference/wine_predictor/config/#wine_predictor.config.load_model_config","title":"load_model_config","text":"<pre><code>load_model_config(model_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Load model-specific configuration from configs/model/.yaml."},{"location":"reference/wine_predictor/dataset/","title":"<code>wine_predictor.dataset</code>","text":""},{"location":"reference/wine_predictor/dataset/#wine_predictor.dataset","title":"wine_predictor.dataset","text":""},{"location":"reference/wine_predictor/dataset/#wine_predictor.dataset.load_wine_data","title":"load_wine_data","text":"<pre><code>load_wine_data(\n    config: TrainingConfig = TRAINING_CONFIG,\n) -&gt; pd.DataFrame\n</code></pre> <p>Load WineQT dataset from disk and perform basic validation.</p>"},{"location":"reference/wine_predictor/experiments/","title":"<code>wine_predictor.experiments</code>","text":""},{"location":"reference/wine_predictor/experiments/#wine_predictor.experiments","title":"wine_predictor.experiments","text":""},{"location":"reference/wine_predictor/features/","title":"<code>wine_predictor.features</code>","text":""},{"location":"reference/wine_predictor/features/#wine_predictor.features","title":"wine_predictor.features","text":""},{"location":"reference/wine_predictor/features/#wine_predictor.features.create_features_and_target","title":"create_features_and_target","text":"<pre><code>create_features_and_target(\n    df: DataFrame, config: TrainingConfig = TRAINING_CONFIG\n) -&gt; Tuple[pd.DataFrame, pd.Series]\n</code></pre> <p>Split dataframe into features X and target y.</p>"},{"location":"reference/wine_predictor/mlflow_utils/","title":"<code>wine_predictor.mlflow_utils</code>","text":""},{"location":"reference/wine_predictor/mlflow_utils/#wine_predictor.mlflow_utils","title":"wine_predictor.mlflow_utils","text":""},{"location":"reference/wine_predictor/mlflow_utils/#wine_predictor.mlflow_utils.configure_mlflow","title":"configure_mlflow","text":"<pre><code>configure_mlflow(\n    tracking_uri: str = DEFAULT_TRACKING_URI,\n    experiment_name: str = DEFAULT_EXPERIMENT_NAME,\n    artifact_location: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Configure MLflow tracking and ensure the experiment exists.</p>"},{"location":"reference/wine_predictor/mlflow_utils/#wine_predictor.mlflow_utils.log_model_sklearn","title":"log_model_sklearn","text":"<pre><code>log_model_sklearn(model: Any, name: str = 'model') -&gt; None\n</code></pre> <p>Log a sklearn model to MLflow. Uses the newer <code>name=</code> API when available, falling back to older <code>artifact_path=</code> style for compatibility.</p>"},{"location":"reference/wine_predictor/mlflow_utils/#wine_predictor.mlflow_utils.training_run","title":"training_run","text":"<pre><code>training_run(\n    *,\n    default_run_name: str = \"run\",\n    default_tags: Optional[Dict[str, Any]] = None,\n    tracking_uri: str = DEFAULT_TRACKING_URI,\n    experiment_name: str = DEFAULT_EXPERIMENT_NAME,\n    artifact_location: Optional[str] = None,\n    log_model: bool = True\n) -&gt; Callable[[Callable[..., Any]], Callable[..., Any]]\n</code></pre> <p>Decorator for MLflow experiment tracking.</p>"},{"location":"reference/wine_predictor/modeling/predict/","title":"<code>wine_predictor.modeling.predict</code>","text":""},{"location":"reference/wine_predictor/modeling/predict/#wine_predictor.modeling.predict","title":"wine_predictor.modeling.predict","text":""},{"location":"reference/wine_predictor/modeling/predict/#wine_predictor.modeling.predict.predict_from_dataframe","title":"predict_from_dataframe","text":"<pre><code>predict_from_dataframe(\n    model: Pipeline,\n    df: DataFrame,\n    config: TrainingConfig = TRAINING_CONFIG,\n) -&gt; pd.Series\n</code></pre> <p>Run predictions on a dataframe that has the same feature columns as the training data.</p>"},{"location":"reference/wine_predictor/modeling/predict/#wine_predictor.modeling.predict.predict_from_dataframe--parameters","title":"Parameters","text":"<p>model:     Trained sklearn Pipeline. df:     Dataframe containing at least the feature columns. config:     Training configuration with feature column names.</p>"},{"location":"reference/wine_predictor/modeling/predict/#wine_predictor.modeling.predict.predict_from_dataframe--returns","title":"Returns","text":"<p>pd.Series     Predicted labels.</p>"},{"location":"reference/wine_predictor/modeling/predict/#wine_predictor.modeling.predict.predict_from_records","title":"predict_from_records","text":"<pre><code>predict_from_records(\n    model: Pipeline,\n    records: Iterable[dict],\n    config: TrainingConfig = TRAINING_CONFIG,\n) -&gt; pd.Series\n</code></pre> <p>Run predictions on a list of dicts with feature values.</p>"},{"location":"reference/wine_predictor/modeling/train/","title":"<code>wine_predictor.modeling.train</code>","text":""},{"location":"reference/wine_predictor/modeling/train/#wine_predictor.modeling.train","title":"wine_predictor.modeling.train","text":""},{"location":"reference/wine_predictor/pipelines/clearml_pipeline/","title":"<code>wine_predictor.pipelines.clearml_pipeline</code>","text":""},{"location":"reference/wine_predictor/pipelines/clearml_pipeline/#wine_predictor.pipelines.clearml_pipeline","title":"wine_predictor.pipelines.clearml_pipeline","text":""},{"location":"reference/wine_predictor/pipelines/evaluate/","title":"<code>wine_predictor.pipelines.evaluate</code>","text":""},{"location":"reference/wine_predictor/pipelines/evaluate/#wine_predictor.pipelines.evaluate","title":"wine_predictor.pipelines.evaluate","text":""},{"location":"reference/wine_predictor/pipelines/notify/","title":"<code>wine_predictor.pipelines.notify</code>","text":""},{"location":"reference/wine_predictor/pipelines/notify/#wine_predictor.pipelines.notify","title":"wine_predictor.pipelines.notify","text":""},{"location":"reference/wine_predictor/reporting/generate_experiment_report/","title":"<code>wine_predictor.reporting.generate_experiment_report</code>","text":""},{"location":"reference/wine_predictor/reporting/generate_experiment_report/#wine_predictor.reporting.generate_experiment_report","title":"wine_predictor.reporting.generate_experiment_report","text":""}]}